{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FN6815 Numerical Methods for Financial Instrument Pricing\n",
    "\n",
    "# Lecture 5: Solve Multiple Equations\n",
    "\n",
    "-   Dr. Yang Ye\n",
    "-   Email: yy@runchee.com\n",
    "-   2023/2024 Mini Term 5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap\n",
    "\n",
    "In the previous lecture, we discussed several methods for solving non-linear equation:\n",
    "\n",
    "1. **Newton-Raphson method**: This method is used to find roots of $f(x) = 0$ when $f'(x)$ is known.\n",
    "2. **Secant method**: This method is also used to find roots of $f(x) = 0$, but it doesn't require knowledge of $f'(x)$.\n",
    "3. **Bisection method**: This method is used to find roots of $f(x) - y = 0$ within a known interval $[a,b]$ where $f(a)f(b)<0$.\n",
    "\n",
    "### Discussion:\n",
    "\n",
    "When considering the generalization of these methods to solve a system of equations rather than a single equation, which method is viable?\n",
    "\n",
    "**Bisection Method**: In n-dimensions, for the bisection method to work, we need to find a range such that $f(\\vec{x_a}) \\cdot f(\\vec{x_b}) < 0$. This can be challenging in higher dimensions.\n",
    "\n",
    "**Newton's Method**: Newton's method, on the other hand, doesn't require a range but only a starting point. It can be generalized to n-dimensions using Jacobian matrix, making it more suitable for solving systems of equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solve for Multiple Equations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Solving Linear Equations\n",
    "\n",
    "**Gaussian Elimination** is a prevalent and robust method for solving systems of linear equations. It systematically reduces the system to a form from which the solution can be directly read.\n",
    "\n",
    "Python's `numpy` package provides a module `linalg` that includes a function `solve()`. It solves a system of linear equations in the form $Ax=b$. with `x = numpy.linalg.solve(A, b)`.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">Question: Which equation below is linear?</div>\n",
    "\n",
    "1. $3x_1 + 4x_2 - 3 = -5x_3$\n",
    "2. $\\frac{-x_1 + x_2}{x_3} = 2$\n",
    "3. $x_1x_2 + x_3 = 5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Solve for below linear equations\n",
    "\n",
    "$\\begin{cases}\n",
    " 3x_1 + 4x_2 - 3 = 0 \\\\ \n",
    " x_1 + x_2 = 5\n",
    "\\end{cases}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:23.965878Z",
     "iopub.status.busy": "2024-03-01T14:12:23.965878Z",
     "iopub.status.idle": "2024-03-01T14:12:24.182650Z",
     "shell.execute_reply": "2024-03-01T14:12:24.182650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17. -12.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[3, 4], [1, 1]])\n",
    "b = np.array([3, 5])\n",
    "x = np.linalg.solve(A, b)\n",
    "print(x)\n",
    "\n",
    "assert np.allclose(np.dot(A, x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, use inv method, $x = A^{-1}b$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.214345Z",
     "iopub.status.busy": "2024-03-01T14:12:24.213340Z",
     "iopub.status.idle": "2024-03-01T14:12:24.218634Z",
     "shell.execute_reply": "2024-03-01T14:12:24.218120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17. -12.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "x = np.dot(A_inv, b)\n",
    "print(x)\n",
    "\n",
    "assert np.allclose(np.dot(A, x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Solve Non-linear Equations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Taylor expansions for multi-variable functions\n",
    "\n",
    "The concept behind Newton's method for solving a single equation can be extended to multiple variables. The idea is to iteratively approximate the nonlinear function $f$ at a point $\\mathbf{x}_i$ by a linear function and find its root $\\mathbf{x}_{i+1}$. This process is repeated until the root approximation improves insignificantly.\n",
    "\n",
    "In the case of $n$ variables, we need to approximate a vector function $\\mathbf{F}(\\vec{\\mathbf{x}})$ by some linear function $\\tilde{\\mathbf{F}} = \\mathbf{J}\\vec{\\mathbf{x}} + \\mathbf{c}$. Here, $\\mathbf{J}$ is an $n\\times n$ matrix (the Jacobian matrix of $\\mathbf{F}$), and $\\mathbf{c}$ is a vector of length $n$.\n",
    "\n",
    "How to obtain the linear form of $\\mathbf{F}$ at $\\vec{\\mathbf{x}}_i$? The Taylor series expansion. We use the first two terms of the expansion to form the linear approximation:\n",
    "\n",
    "$$\\mathbf{F}(\\vec{\\mathbf{x}}) \\approx \\mathbf{F}(\\vec{\\mathbf{x}_i}) + \\mathbf{J}(\\vec{\\mathbf{x}_i})(\\vec{\\mathbf{x}} - \\vec{\\mathbf{x}_i})$$\n",
    "\n",
    "This equation represents the linear approximation of $\\mathbf{F}$ around the point $\\mathbf{x}_i$.\n",
    "\n",
    "The next terms in the expansions are omitted here and of ths scale\n",
    "$||\\vec{\\mathbf{x}}-\\vec{\\mathbf{x}_i}||^2$, which are assumed to be small and negligible compared with the two terms above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Jacobian $\\nabla$ or $\\mathbf{J}$\n",
    "\n",
    "_Jacobian_ $\\mathbf{J}$ of vector function $\\mathbf{F}$ is the matrix of all the partial derivatives\n",
    "of $\\mathbf{F}$. Component $(i,j)$ in $\\nabla\\mathbf{F}$ is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F_i}{\\partial x_j}\\thinspace .\n",
    "$$\n",
    "\n",
    "For 2-d vector function $\\mathbf{F}$, We can then write\n",
    "\n",
    "$$\n",
    "\\mathbf{J} = \\left(\\begin{array}{ll}\n",
    "\\frac{\\partial F_0}{\\partial x_0} & \\frac{\\partial F_0}{\\partial x_1}\\\\\n",
    "\\frac{\\partial F_1}{\\partial x_0} & \\frac{\\partial F_1}{\\partial x_1}\n",
    "\\end{array}\\right)\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Newton's method for n-dimension\n",
    "\n",
    "The Newton-Raphson method for one dimension is given by:\n",
    "\n",
    "$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)},\\quad n=0,1,2,\\ldots$$\n",
    "\n",
    "We can rewrite this as:\n",
    "\n",
    "$$\n",
    "f(x_n)+f'(x_n)(x_{n+1} - x_n) = 0\n",
    "$$\n",
    "\n",
    "For multiple dimensions, we use the Jacobian matrix to obtain the linear equation at $\\mathbf{x}_i$,\n",
    "\n",
    "$$\n",
    "\\mathbf{F}(\\vec{\\mathbf{x}}) \\approx \\mathbf{F}(\\vec{\\mathbf{x}_i}) + \\mathbf{J}(\\vec{\\mathbf{x}_i})(\\vec{\\mathbf{x}} - \\vec{\\mathbf{x}_i})\n",
    "$$\n",
    "\n",
    "And then solve for $\\mathbf{x}_{i+1}$, by setting $\\mathbf{F}(\\mathbf{x}_{i+1})=0$.\n",
    "\n",
    "$$\n",
    "\\mathbf{F}(\\vec{\\mathbf{x}_i}) + \\mathbf{J}(\\vec{{x}_i})(\\vec{{x}_{i+1}}-\\vec{{x}_i}) = {0},\n",
    "$$\n",
    "\n",
    "We use symbol $\\mathbf{\\delta}$ for the the change in $\\mathbf{x}$ to the next iteration, $\\mathbf{x}_{i+1} = \\mathbf{x}_i + \\mathbf{\\delta}$.\n",
    "\n",
    "$$\\mathbf{J}(\\mathbf{x}_i)\\mathbf{\\delta} = -\\mathbf{F}(\\mathbf{x}_i),$$\n",
    "\n",
    "We then go through the iterative process of following steps:\n",
    "\n",
    "1. Solve the linear system $\\mathbf{J}(\\mathbf{x}_i)\\mathbf{\\delta} = -\\mathbf{F}(\\mathbf{x}_i)$ to find $\\mathbf{\\delta}$.\n",
    "2. Update the estimate: $\\mathbf{x}_{i+1} = \\mathbf{x}_i + \\mathbf{\\delta}$.\n",
    "3. Check the exit condition: if the norm of $\\mathbf{F}(\\mathbf{x}_i)$ is sufficiently small, exit the loop.\n",
    "   Because $\\mathbf{F}(\\mathbf{x}_i)$ is a vector, we use `linalg.norm` to check all its values are close to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple Python example using the Newton's method for a system of equations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.220641Z",
     "iopub.status.busy": "2024-03-01T14:12:24.220641Z",
     "iopub.status.idle": "2024-03-01T14:12:24.228333Z",
     "shell.execute_reply": "2024-03-01T14:12:24.228333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.ndarray[typing.Any, numpy.dtype[+_ScalarType_co]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "print(npt.NDArray)\n",
    "\n",
    "\n",
    "def Newton_system(F: Callable, J: Callable, x: npt.NDArray, eps: float):\n",
    "    \"\"\"\n",
    "    Solve nonlinear system F=0 by Newton's method.\n",
    "\n",
    "    J is the Jacobian of F.\n",
    "    Both F and J must be functions of x.\n",
    "    x holds the start value.\n",
    "    The iteration continues until ||F|| < eps.\n",
    "    \"\"\"\n",
    "    F_value = F(x)\n",
    "    F_norm = np.linalg.norm(F_value, ord=2)  # l2 norm of vector\n",
    "    iteration_counter = 0\n",
    "    while abs(F_norm) > eps and iteration_counter < 100:\n",
    "        # Inverse is more expensive calculation than solving\n",
    "        # Use inverse for simple verification only\n",
    "        # Inverse: delta = np.matmul(np.linalg.inv(J(x)), -F_value)\n",
    "        if F_value.shape == (1,):\n",
    "            delta = 1 / J(x) * -F_value\n",
    "        else:\n",
    "            delta = np.linalg.solve(J(x), -F_value)\n",
    "        x = x + delta\n",
    "        F_value = F(x)\n",
    "        F_norm = np.linalg.norm(F_value, ord=2)\n",
    "        iteration_counter += 1\n",
    "\n",
    "    # Here, either a solution is found, or too many iterations\n",
    "    if abs(F_norm) > eps:\n",
    "        return None, iteration_counter\n",
    "    return x, iteration_counter\n",
    "\n",
    "\n",
    "def test_Newton_system1(F, J, expected, start_x, tol=1e-4):\n",
    "    x, n = Newton_system(F, J, x=start_x, eps=tol)\n",
    "    print(f\"x={x}, n={n}\")\n",
    "    error_norm = np.linalg.norm(expected - x, ord=2)\n",
    "    assert error_norm < tol, \"norm of error =%g\" % error_norm\n",
    "    print(\"norm of error =%g\" % error_norm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Try it Out\n",
    "\n",
    "#### 2.3.1 1-D linear system\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y & = 3x + 3 \\\\\n",
    "\\frac {\\mathrm{d}y} {\\mathrm{d}x} & = 3\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.230393Z",
     "iopub.status.busy": "2024-03-01T14:12:24.230393Z",
     "iopub.status.idle": "2024-03-01T14:12:24.236504Z",
     "shell.execute_reply": "2024-03-01T14:12:24.236504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[-1.], n=1\n",
      "norm of error =0\n"
     ]
    }
   ],
   "source": [
    "# We can test the function Newton_system with the 2Ã—2 system (172)-(173):\n",
    "F = lambda x: np.array(\n",
    "    [\n",
    "        3 * x + 3,\n",
    "    ]\n",
    ")\n",
    "J = lambda _x: np.array([3])\n",
    "\n",
    "test_Newton_system1(F, J, expected=np.array(-1), start_x=np.array(100))\n",
    "# Linear function's n == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 2-D linear system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.239866Z",
     "iopub.status.busy": "2024-03-01T14:12:24.239866Z",
     "iopub.status.idle": "2024-03-01T14:12:24.243730Z",
     "shell.execute_reply": "2024-03-01T14:12:24.243730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17. -12.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3, 4], [1, 1]])\n",
    "b = np.array([3, 5])\n",
    "x = np.linalg.solve(A, b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.246480Z",
     "iopub.status.busy": "2024-03-01T14:12:24.245101Z",
     "iopub.status.idle": "2024-03-01T14:12:24.249894Z",
     "shell.execute_reply": "2024-03-01T14:12:24.249894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[ 17. -12.], n=1\n",
      "norm of error =3.97205e-15\n"
     ]
    }
   ],
   "source": [
    "# Use Newton's method\n",
    "F = lambda x: np.array([3 * x[0] + 4 * x[1] - 3, 1 * x[0] + 1 * x[1] - 5])\n",
    "J = lambda _x: np.array([[3, 4], [1, 1]])\n",
    "\n",
    "test_Newton_system1(F, J, expected=np.array([17, -12]), start_x=np.array([1, 2]))\n",
    "# For linear function's n == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.3 Non-linear Equations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve for below non-linear equations\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y = 3x + sin(x)^2 \\\\\n",
    "y^2 = cos(x)\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.251756Z",
     "iopub.status.busy": "2024-03-01T14:12:24.251756Z",
     "iopub.status.idle": "2024-03-01T14:12:24.259020Z",
     "shell.execute_reply": "2024-03-01T14:12:24.259020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[-0.36456854 -0.96658041], n=6\n",
      "norm of error =2.83469e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.05223608e-11,  5.44045708e-09])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def F(x):\n",
    "    x0, x1 = x[0], x[1]\n",
    "    return np.array([x1 - 3 * x0 - np.sin(x0) ** 2, x1**2 - np.cos(x0)])\n",
    "\n",
    "\n",
    "def J(x):\n",
    "    x0, x1 = x[0], x[1]\n",
    "    return np.array([[-2 * np.sin(x0) * np.cos(x0) - 3, 1], [np.sin(x0), 2 * x1]])\n",
    "\n",
    "\n",
    "expected = np.array(\n",
    "    [-0.36456854, -0.96658041],\n",
    ")\n",
    "test_Newton_system1(F, J, expected, start_x=np.array([2.0, -1.0]), tol=1e-8)\n",
    "F([-0.36456854, -0.96658041])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Summary\n",
    "\n",
    "To solve for n-dimensional non-linear equation, Newton's method has the advantage of speed and convergence. The method requires the Jacobian matrix of the function, and iteratively updates the estimate of the root until the function value is close to zero.\n",
    "\n",
    "The Newton's method for solving systems of equations in vector form is given by:\n",
    "\n",
    "$$\\vec{x}_{n+1} = \\vec{x}_n - [J(\\vec{x}_n)]^{-1} \\cdot \\vec{f}(\\vec{x}_n)$$\n",
    "\n",
    "In this equation, $\\vec{x}_n$ is the current estimate of the solution, $J(\\vec{x}_n)$ is the Jacobian matrix evaluated at $\\vec{x}_n$, and $\\vec{f}(\\vec{x}_n)$ is the vector function evaluated at $\\vec{x}_n$. The term $[J(\\vec{x}_n)]^{-1} \\cdot \\vec{f}(\\vec{x}_n)$ represents the step taken in the direction of the solution.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assignment\n",
    "\n",
    "### Q1. Gradient Descent\n",
    "\n",
    "Gradient Descent, a first-order iterative optimization algorithm, is used to find a local minimum of a differentiable function. It's built on Newton's method and was first suggested by Augustin-Louis Cauchy in 1847. Jacques Hadamard independently proposed a similar method in 1907.\n",
    "\n",
    "The algorithm uses the Jacobian matrix at position $\\bar{x}_n$ to iteratively update $\\bar{x}_{n+1}$, aiming to reach a local or global minimum. The learning rate, denoted as $\\eta$, influences the step size in each iteration:\n",
    "\n",
    "$$\\bar{x}{n+1} = \\bar{x}{n} - J * \\eta$$\n",
    "\n",
    "The learning rate must be carefully chosen. If it's too large, the algorithm may oscillate around the minimum. If it's too small, the convergence may be slow.\n",
    "\n",
    "Consider the unimodal function $z^2 = (x - x_c)^2 + (y - y_c)^2$ with $x_c = 2$ and $y_c = -1$. We want to find the minimum of this function using gradient descent.\n",
    "\n",
    "Here's a prototype for the Python function solve() that implements the gradient descent algorithm:\n",
    "\n",
    "```python\n",
    "def solve(xs_init, _f_func, _j_func, ...)\n",
    "```\n",
    "\n",
    "In this function, `xs_init` is the initial guess, `_f_func` is the function to minimize, `_j_func` is the Jacobian of `_f_func`, `learning_rate` is the learning rate, and `precision` is the desired precision of the result be reached.\n",
    "\n",
    "You can experiment with different learning rates and initial guesses to observe the behavior of the algorithm. while\n",
    "\n",
    "Find two set of parameters such that\n",
    "\n",
    "1. Not able to find the answer with whatever number of steps.\n",
    "2. A suitable learning rate and initial guess can help the algorithm find the minimum $(2, -1)$ within $0.01$ precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 4, -2]), 0, [array([0, 0]), array([ 4, -2])]),\n",
       " (array([ 1.99956994, -0.99978497]),\n",
       "  417,\n",
       "  [array([0, 0]),\n",
       "   array([ 0.04, -0.02]),\n",
       "   array([ 0.0792, -0.0396]),\n",
       "   array([ 0.117616, -0.058808]),\n",
       "   array([ 0.15526368, -0.07763184]),\n",
       "   array([ 0.19215841, -0.0960792 ]),\n",
       "   array([ 0.22831524, -0.11415762]),\n",
       "   array([ 0.26374893, -0.13187447]),\n",
       "   array([ 0.29847395, -0.14923698]),\n",
       "   array([ 0.33250448, -0.16625224]),\n",
       "   array([ 0.36585439, -0.18292719]),\n",
       "   array([ 0.3985373 , -0.19926865]),\n",
       "   array([ 0.43056655, -0.21528328]),\n",
       "   array([ 0.46195522, -0.23097761]),\n",
       "   array([ 0.49271612, -0.24635806]),\n",
       "   array([ 0.52286179, -0.2614309 ]),\n",
       "   array([ 0.55240456, -0.27620228]),\n",
       "   array([ 0.58135647, -0.29067823]),\n",
       "   array([ 0.60972934, -0.30486467]),\n",
       "   array([ 0.63753475, -0.31876738]),\n",
       "   array([ 0.66478406, -0.33239203]),\n",
       "   array([ 0.69148838, -0.34574419]),\n",
       "   array([ 0.71765861, -0.3588293 ]),\n",
       "   array([ 0.74330544, -0.37165272]),\n",
       "   array([ 0.76843933, -0.38421966]),\n",
       "   array([ 0.79307054, -0.39653527]),\n",
       "   array([ 0.81720913, -0.40860456]),\n",
       "   array([ 0.84086495, -0.42043247]),\n",
       "   array([ 0.86404765, -0.43202382]),\n",
       "   array([ 0.8867667 , -0.44338335]),\n",
       "   array([ 0.90903136, -0.45451568]),\n",
       "   array([ 0.93085073, -0.46542537]),\n",
       "   array([ 0.95223372, -0.47611686]),\n",
       "   array([ 0.97318904, -0.48659452]),\n",
       "   array([ 0.99372526, -0.49686263]),\n",
       "   array([ 1.01385076, -0.50692538]),\n",
       "   array([ 1.03357374, -0.51678687]),\n",
       "   array([ 1.05290227, -0.52645113]),\n",
       "   array([ 1.07184422, -0.53592211]),\n",
       "   array([ 1.09040734, -0.54520367]),\n",
       "   array([ 1.10859919, -0.5542996 ]),\n",
       "   array([ 1.12642721, -0.5632136 ]),\n",
       "   array([ 1.14389866, -0.57194933]),\n",
       "   array([ 1.16102069, -0.58051035]),\n",
       "   array([ 1.17780028, -0.58890014]),\n",
       "   array([ 1.19424427, -0.59712214]),\n",
       "   array([ 1.21035939, -0.60517969]),\n",
       "   array([ 1.2261522, -0.6130761]),\n",
       "   array([ 1.24162915, -0.62081458]),\n",
       "   array([ 1.25679657, -0.62839829]),\n",
       "   array([ 1.27166064, -0.63583032]),\n",
       "   array([ 1.28622743, -0.64311371]),\n",
       "   array([ 1.30050288, -0.65025144]),\n",
       "   array([ 1.31449282, -0.65724641]),\n",
       "   array([ 1.32820296, -0.66410148]),\n",
       "   array([ 1.34163891, -0.67081945]),\n",
       "   array([ 1.35480613, -0.67740306]),\n",
       "   array([ 1.36771 , -0.683855]),\n",
       "   array([ 1.3803558, -0.6901779]),\n",
       "   array([ 1.39274869, -0.69637434]),\n",
       "   array([ 1.40489371, -0.70244686]),\n",
       "   array([ 1.41679584, -0.70839792]),\n",
       "   array([ 1.42845992, -0.71422996]),\n",
       "   array([ 1.43989073, -0.71994536]),\n",
       "   array([ 1.45109291, -0.72554646]),\n",
       "   array([ 1.46207105, -0.73103553]),\n",
       "   array([ 1.47282963, -0.73641482]),\n",
       "   array([ 1.48337304, -0.74168652]),\n",
       "   array([ 1.49370558, -0.74685279]),\n",
       "   array([ 1.50383147, -0.75191573]),\n",
       "   array([ 1.51375484, -0.75687742]),\n",
       "   array([ 1.52347974, -0.76173987]),\n",
       "   array([ 1.53301015, -0.76650507]),\n",
       "   array([ 1.54234994, -0.77117497]),\n",
       "   array([ 1.55150294, -0.77575147]),\n",
       "   array([ 1.56047288, -0.78023644]),\n",
       "   array([ 1.56926343, -0.78463171]),\n",
       "   array([ 1.57787816, -0.78893908]),\n",
       "   array([ 1.5863206, -0.7931603]),\n",
       "   array([ 1.59459418, -0.79729709]),\n",
       "   array([ 1.6027023 , -0.80135115]),\n",
       "   array([ 1.61064825, -0.80532413]),\n",
       "   array([ 1.61843529, -0.80921764]),\n",
       "   array([ 1.62606658, -0.81303329]),\n",
       "   array([ 1.63354525, -0.81677263]),\n",
       "   array([ 1.64087435, -0.82043717]),\n",
       "   array([ 1.64805686, -0.82402843]),\n",
       "   array([ 1.65509572, -0.82754786]),\n",
       "   array([ 1.66199381, -0.8309969 ]),\n",
       "   array([ 1.66875393, -0.83437697]),\n",
       "   array([ 1.67537885, -0.83768943]),\n",
       "   array([ 1.68187128, -0.84093564]),\n",
       "   array([ 1.68823385, -0.84411693]),\n",
       "   array([ 1.69446917, -0.84723459]),\n",
       "   array([ 1.70057979, -0.85028989]),\n",
       "   array([ 1.70656819, -0.8532841 ]),\n",
       "   array([ 1.71243683, -0.85621842]),\n",
       "   array([ 1.71818809, -0.85909405]),\n",
       "   array([ 1.72382433, -0.86191217]),\n",
       "   array([ 1.72934785, -0.86467392]),\n",
       "   array([ 1.73476089, -0.86738044]),\n",
       "   array([ 1.74006567, -0.87003284]),\n",
       "   array([ 1.74526436, -0.87263218]),\n",
       "   array([ 1.75035907, -0.87517953]),\n",
       "   array([ 1.75535189, -0.87767594]),\n",
       "   array([ 1.76024485, -0.88012243]),\n",
       "   array([ 1.76503995, -0.88251998]),\n",
       "   array([ 1.76973915, -0.88486958]),\n",
       "   array([ 1.77434437, -0.88717219]),\n",
       "   array([ 1.77885748, -0.88942874]),\n",
       "   array([ 1.78328033, -0.89164017]),\n",
       "   array([ 1.78761473, -0.89380736]),\n",
       "   array([ 1.79186243, -0.89593122]),\n",
       "   array([ 1.79602518, -0.89801259]),\n",
       "   array([ 1.80010468, -0.90005234]),\n",
       "   array([ 1.80410259, -0.90205129]),\n",
       "   array([ 1.80802054, -0.90401027]),\n",
       "   array([ 1.81186012, -0.90593006]),\n",
       "   array([ 1.81562292, -0.90781146]),\n",
       "   array([ 1.81931046, -0.90965523]),\n",
       "   array([ 1.82292425, -0.91146213]),\n",
       "   array([ 1.82646577, -0.91323288]),\n",
       "   array([ 1.82993645, -0.91496823]),\n",
       "   array([ 1.83333772, -0.91666886]),\n",
       "   array([ 1.83667097, -0.91833549]),\n",
       "   array([ 1.83993755, -0.91996878]),\n",
       "   array([ 1.8431388, -0.9215694]),\n",
       "   array([ 1.84627602, -0.92313801]),\n",
       "   array([ 1.8493505 , -0.92467525]),\n",
       "   array([ 1.85236349, -0.92618175]),\n",
       "   array([ 1.85531622, -0.92765811]),\n",
       "   array([ 1.8582099 , -0.92910495]),\n",
       "   array([ 1.8610457 , -0.93052285]),\n",
       "   array([ 1.86382479, -0.93191239]),\n",
       "   array([ 1.86654829, -0.93327415]),\n",
       "   array([ 1.86921733, -0.93460866]),\n",
       "   array([ 1.87183298, -0.93591649]),\n",
       "   array([ 1.87439632, -0.93719816]),\n",
       "   array([ 1.87690839, -0.9384542 ]),\n",
       "   array([ 1.87937023, -0.93968511]),\n",
       "   array([ 1.88178282, -0.94089141]),\n",
       "   array([ 1.88414716, -0.94207358]),\n",
       "   array([ 1.88646422, -0.94323211]),\n",
       "   array([ 1.88873494, -0.94436747]),\n",
       "   array([ 1.89096024, -0.94548012]),\n",
       "   array([ 1.89314103, -0.94657052]),\n",
       "   array([ 1.89527821, -0.94763911]),\n",
       "   array([ 1.89737265, -0.94868632]),\n",
       "   array([ 1.8994252, -0.9497126]),\n",
       "   array([ 1.90143669, -0.95071835]),\n",
       "   array([ 1.90340796, -0.95170398]),\n",
       "   array([ 1.9053398, -0.9526699]),\n",
       "   array([ 1.907233 , -0.9536165]),\n",
       "   array([ 1.90908834, -0.95454417]),\n",
       "   array([ 1.91090658, -0.95545329]),\n",
       "   array([ 1.91268844, -0.95634422]),\n",
       "   array([ 1.91443468, -0.95721734]),\n",
       "   array([ 1.91614598, -0.95807299]),\n",
       "   array([ 1.91782306, -0.95891153]),\n",
       "   array([ 1.9194666, -0.9597333]),\n",
       "   array([ 1.92107727, -0.96053863]),\n",
       "   array([ 1.92265572, -0.96132786]),\n",
       "   array([ 1.92420261, -0.9621013 ]),\n",
       "   array([ 1.92571856, -0.96285928]),\n",
       "   array([ 1.92720419, -0.96360209]),\n",
       "   array([ 1.9286601 , -0.96433005]),\n",
       "   array([ 1.9300869 , -0.96504345]),\n",
       "   array([ 1.93148516, -0.96574258]),\n",
       "   array([ 1.93285546, -0.96642773]),\n",
       "   array([ 1.93419835, -0.96709917]),\n",
       "   array([ 1.93551438, -0.96775719]),\n",
       "   array([ 1.93680409, -0.96840205]),\n",
       "   array([ 1.93806801, -0.96903401]),\n",
       "   array([ 1.93930665, -0.96965333]),\n",
       "   array([ 1.94052052, -0.97026026]),\n",
       "   array([ 1.94171011, -0.97085505]),\n",
       "   array([ 1.94287591, -0.97143795]),\n",
       "   array([ 1.94401839, -0.97200919]),\n",
       "   array([ 1.94513802, -0.97256901]),\n",
       "   array([ 1.94623526, -0.97311763]),\n",
       "   array([ 1.94731056, -0.97365528]),\n",
       "   array([ 1.94836434, -0.97418217]),\n",
       "   array([ 1.94939706, -0.97469853]),\n",
       "   array([ 1.95040912, -0.97520456]),\n",
       "   array([ 1.95140093, -0.97570047]),\n",
       "   array([ 1.95237292, -0.97618646]),\n",
       "   array([ 1.95332546, -0.97666273]),\n",
       "   array([ 1.95425895, -0.97712947]),\n",
       "   array([ 1.95517377, -0.97758688]),\n",
       "   array([ 1.95607029, -0.97803515]),\n",
       "   array([ 1.95694889, -0.97847444]),\n",
       "   array([ 1.95780991, -0.97890495]),\n",
       "   array([ 1.95865371, -0.97932686]),\n",
       "   array([ 1.95948064, -0.97974032]),\n",
       "   array([ 1.96029102, -0.98014551]),\n",
       "   array([ 1.9610852, -0.9805426]),\n",
       "   array([ 1.9618635 , -0.98093175]),\n",
       "   array([ 1.96262623, -0.98131312]),\n",
       "   array([ 1.96337371, -0.98168685]),\n",
       "   array([ 1.96410623, -0.98205312]),\n",
       "   array([ 1.96482411, -0.98241205]),\n",
       "   array([ 1.96552762, -0.98276381]),\n",
       "   array([ 1.96621707, -0.98310854]),\n",
       "   array([ 1.96689273, -0.98344637]),\n",
       "   array([ 1.96755488, -0.98377744]),\n",
       "   array([ 1.96820378, -0.98410189]),\n",
       "   array([ 1.9688397 , -0.98441985]),\n",
       "   array([ 1.96946291, -0.98473145]),\n",
       "   array([ 1.97007365, -0.98503683]),\n",
       "   array([ 1.97067218, -0.98533609]),\n",
       "   array([ 1.97125873, -0.98562937]),\n",
       "   array([ 1.97183356, -0.98591678]),\n",
       "   array([ 1.97239689, -0.98619844]),\n",
       "   array([ 1.97294895, -0.98647448]),\n",
       "   array([ 1.97348997, -0.98674499]),\n",
       "   array([ 1.97402017, -0.98701009]),\n",
       "   array([ 1.97453977, -0.98726988]),\n",
       "   array([ 1.97504897, -0.98752449]),\n",
       "   array([ 1.97554799, -0.987774  ]),\n",
       "   array([ 1.97603703, -0.98801852]),\n",
       "   array([ 1.97651629, -0.98825815]),\n",
       "   array([ 1.97698597, -0.98849298]),\n",
       "   array([ 1.97744625, -0.98872312]),\n",
       "   array([ 1.97789732, -0.98894866]),\n",
       "   array([ 1.97833938, -0.98916969]),\n",
       "   array([ 1.97877259, -0.98938629]),\n",
       "   array([ 1.97919714, -0.98959857]),\n",
       "   array([ 1.97961319, -0.9898066 ]),\n",
       "   array([ 1.98002093, -0.99001047]),\n",
       "   array([ 1.98042051, -0.99021026]),\n",
       "   array([ 1.9808121 , -0.99040605]),\n",
       "   array([ 1.98119586, -0.99059793]),\n",
       "   array([ 1.98157194, -0.99078597]),\n",
       "   array([ 1.9819405 , -0.99097025]),\n",
       "   array([ 1.98230169, -0.99115085]),\n",
       "   array([ 1.98265566, -0.99132783]),\n",
       "   array([ 1.98300255, -0.99150127]),\n",
       "   array([ 1.9833425 , -0.99167125]),\n",
       "   array([ 1.98367565, -0.99183782]),\n",
       "   array([ 1.98400213, -0.99200107]),\n",
       "   array([ 1.98432209, -0.99216105]),\n",
       "   array([ 1.98463565, -0.99231782]),\n",
       "   array([ 1.98494294, -0.99247147]),\n",
       "   array([ 1.98524408, -0.99262204]),\n",
       "   array([ 1.9855392, -0.9927696]),\n",
       "   array([ 1.98582841, -0.99291421]),\n",
       "   array([ 1.98611184, -0.99305592]),\n",
       "   array([ 1.98638961, -0.9931948 ]),\n",
       "   array([ 1.98666181, -0.99333091]),\n",
       "   array([ 1.98692858, -0.99346429]),\n",
       "   array([ 1.98719001, -0.993595  ]),\n",
       "   array([ 1.98744621, -0.9937231 ]),\n",
       "   array([ 1.98769728, -0.99384864]),\n",
       "   array([ 1.98794334, -0.99397167]),\n",
       "   array([ 1.98818447, -0.99409223]),\n",
       "   array([ 1.98842078, -0.99421039]),\n",
       "   array([ 1.98865236, -0.99432618]),\n",
       "   array([ 1.98887932, -0.99443966]),\n",
       "   array([ 1.98910173, -0.99455087]),\n",
       "   array([ 1.9893197 , -0.99465985]),\n",
       "   array([ 1.9895333 , -0.99476665]),\n",
       "   array([ 1.98974264, -0.99487132]),\n",
       "   array([ 1.98994778, -0.99497389]),\n",
       "   array([ 1.99014883, -0.99507441]),\n",
       "   array([ 1.99034585, -0.99517293]),\n",
       "   array([ 1.99053893, -0.99526947]),\n",
       "   array([ 1.99072816, -0.99536408]),\n",
       "   array([ 1.99091359, -0.9954568 ]),\n",
       "   array([ 1.99109532, -0.99554766]),\n",
       "   array([ 1.99127341, -0.99563671]),\n",
       "   array([ 1.99144795, -0.99572397]),\n",
       "   array([ 1.99161899, -0.99580949]),\n",
       "   array([ 1.99178661, -0.9958933 ]),\n",
       "   array([ 1.99195088, -0.99597544]),\n",
       "   array([ 1.99211186, -0.99605593]),\n",
       "   array([ 1.99226962, -0.99613481]),\n",
       "   array([ 1.99242423, -0.99621211]),\n",
       "   array([ 1.99257574, -0.99628787]),\n",
       "   array([ 1.99272423, -0.99636211]),\n",
       "   array([ 1.99286974, -0.99643487]),\n",
       "   array([ 1.99301235, -0.99650617]),\n",
       "   array([ 1.9931521 , -0.99657605]),\n",
       "   array([ 1.99328906, -0.99664453]),\n",
       "   array([ 1.99342328, -0.99671164]),\n",
       "   array([ 1.99355481, -0.99677741]),\n",
       "   array([ 1.99368372, -0.99684186]),\n",
       "   array([ 1.99381004, -0.99690502]),\n",
       "   array([ 1.99393384, -0.99696692]),\n",
       "   array([ 1.99405517, -0.99702758]),\n",
       "   array([ 1.99417406, -0.99708703]),\n",
       "   array([ 1.99429058, -0.99714529]),\n",
       "   array([ 1.99440477, -0.99720238]),\n",
       "   array([ 1.99451667, -0.99725834]),\n",
       "   array([ 1.99462634, -0.99731317]),\n",
       "   array([ 1.99473381, -0.99736691]),\n",
       "   array([ 1.99483914, -0.99741957]),\n",
       "   array([ 1.99494235, -0.99747118]),\n",
       "   array([ 1.99504351, -0.99752175]),\n",
       "   array([ 1.99514264, -0.99757132]),\n",
       "   array([ 1.99523978, -0.99761989]),\n",
       "   array([ 1.99533499, -0.99766749]),\n",
       "   array([ 1.99542829, -0.99771414]),\n",
       "   array([ 1.99551972, -0.99775986]),\n",
       "   array([ 1.99560933, -0.99780466]),\n",
       "   array([ 1.99569714, -0.99784857]),\n",
       "   array([ 1.9957832, -0.9978916]),\n",
       "   array([ 1.99586754, -0.99793377]),\n",
       "   array([ 1.99595018, -0.99797509]),\n",
       "   array([ 1.99603118, -0.99801559]),\n",
       "   array([ 1.99611056, -0.99805528]),\n",
       "   array([ 1.99618835, -0.99809417]),\n",
       "   array([ 1.99626458, -0.99813229]),\n",
       "   array([ 1.99633929, -0.99816964]),\n",
       "   array([ 1.9964125 , -0.99820625]),\n",
       "   array([ 1.99648425, -0.99824213]),\n",
       "   array([ 1.99655457, -0.99827728]),\n",
       "   array([ 1.99662348, -0.99831174]),\n",
       "   array([ 1.99669101, -0.9983455 ]),\n",
       "   array([ 1.99675719, -0.99837859]),\n",
       "   array([ 1.99682204, -0.99841102]),\n",
       "   array([ 1.9968856, -0.9984428]),\n",
       "   array([ 1.99694789, -0.99847394]),\n",
       "   array([ 1.99700893, -0.99850447]),\n",
       "   array([ 1.99706875, -0.99853438]),\n",
       "   array([ 1.99712738, -0.99856369]),\n",
       "   array([ 1.99718483, -0.99859242]),\n",
       "   array([ 1.99724113, -0.99862057]),\n",
       "   array([ 1.99729631, -0.99864816]),\n",
       "   array([ 1.99735038, -0.99867519]),\n",
       "   array([ 1.99740338, -0.99870169]),\n",
       "   array([ 1.99745531, -0.99872765]),\n",
       "   array([ 1.9975062, -0.9987531]),\n",
       "   array([ 1.99755608, -0.99877804]),\n",
       "   array([ 1.99760496, -0.99880248]),\n",
       "   array([ 1.99765286, -0.99882643]),\n",
       "   array([ 1.9976998, -0.9988499]),\n",
       "   array([ 1.99774581, -0.9988729 ]),\n",
       "   array([ 1.99779089, -0.99889544]),\n",
       "   array([ 1.99783507, -0.99891754]),\n",
       "   array([ 1.99787837, -0.99893918]),\n",
       "   array([ 1.9979208, -0.9989604]),\n",
       "   array([ 1.99796239, -0.99898119]),\n",
       "   array([ 1.99800314, -0.99900157]),\n",
       "   array([ 1.99804308, -0.99902154]),\n",
       "   array([ 1.99808221, -0.99904111]),\n",
       "   array([ 1.99812057, -0.99906029]),\n",
       "   array([ 1.99815816, -0.99907908]),\n",
       "   array([ 1.998195 , -0.9990975]),\n",
       "   array([ 1.9982311 , -0.99911555]),\n",
       "   array([ 1.99826647, -0.99913324]),\n",
       "   array([ 1.99830114, -0.99915057]),\n",
       "   array([ 1.99833512, -0.99916756]),\n",
       "   array([ 1.99836842, -0.99918421]),\n",
       "   array([ 1.99840105, -0.99920053]),\n",
       "   array([ 1.99843303, -0.99921651]),\n",
       "   array([ 1.99846437, -0.99923218]),\n",
       "   array([ 1.99849508, -0.99924754]),\n",
       "   array([ 1.99852518, -0.99926259]),\n",
       "   array([ 1.99855468, -0.99927734]),\n",
       "   array([ 1.99858358, -0.99929179]),\n",
       "   array([ 1.99861191, -0.99930596]),\n",
       "   array([ 1.99863967, -0.99931984]),\n",
       "   array([ 1.99866688, -0.99933344]),\n",
       "   array([ 1.99869354, -0.99934677]),\n",
       "   array([ 1.99871967, -0.99935984]),\n",
       "   array([ 1.99874528, -0.99937264]),\n",
       "   array([ 1.99877037, -0.99938519]),\n",
       "   array([ 1.99879496, -0.99939748]),\n",
       "   array([ 1.99881907, -0.99940953]),\n",
       "   array([ 1.99884268, -0.99942134]),\n",
       "   array([ 1.99886583, -0.99943292]),\n",
       "   array([ 1.99888851, -0.99944426]),\n",
       "   array([ 1.99891074, -0.99945537]),\n",
       "   array([ 1.99893253, -0.99946626]),\n",
       "   array([ 1.99895388, -0.99947694]),\n",
       "   array([ 1.9989748, -0.9994874]),\n",
       "   array([ 1.9989953 , -0.99949765]),\n",
       "   array([ 1.9990154, -0.9995077]),\n",
       "   array([ 1.99903509, -0.99951755]),\n",
       "   array([ 1.99905439, -0.99952719]),\n",
       "   array([ 1.9990733 , -0.99953665]),\n",
       "   array([ 1.99909183, -0.99954592]),\n",
       "   array([ 1.99911 , -0.999555]),\n",
       "   array([ 1.9991278, -0.9995639]),\n",
       "   array([ 1.99914524, -0.99957262]),\n",
       "   array([ 1.99916234, -0.99958117]),\n",
       "   array([ 1.99917909, -0.99958955]),\n",
       "   array([ 1.99919551, -0.99959775]),\n",
       "   array([ 1.9992116, -0.9996058]),\n",
       "   array([ 1.99922737, -0.99961368]),\n",
       "   array([ 1.99924282, -0.99962141]),\n",
       "   array([ 1.99925796, -0.99962898]),\n",
       "   array([ 1.9992728, -0.9996364]),\n",
       "   array([ 1.99928735, -0.99964367]),\n",
       "   array([ 1.9993016, -0.9996508]),\n",
       "   array([ 1.99931557, -0.99965778]),\n",
       "   array([ 1.99932926, -0.99966463]),\n",
       "   array([ 1.99934267, -0.99967134]),\n",
       "   array([ 1.99935582, -0.99967791]),\n",
       "   array([ 1.9993687 , -0.99968435]),\n",
       "   array([ 1.99938133, -0.99969066]),\n",
       "   array([ 1.9993937 , -0.99969685]),\n",
       "   array([ 1.99940583, -0.99970291]),\n",
       "   array([ 1.99941771, -0.99970886]),\n",
       "   array([ 1.99942936, -0.99971468]),\n",
       "   array([ 1.99944077, -0.99972038]),\n",
       "   array([ 1.99945195, -0.99972598]),\n",
       "   array([ 1.99946292, -0.99973146]),\n",
       "   array([ 1.99947366, -0.99973683]),\n",
       "   array([ 1.99948418, -0.99974209]),\n",
       "   array([ 1.9994945 , -0.99974725]),\n",
       "   array([ 1.99950461, -0.99975231]),\n",
       "   array([ 1.99951452, -0.99975726]),\n",
       "   array([ 1.99952423, -0.99976211]),\n",
       "   array([ 1.99953374, -0.99976687]),\n",
       "   array([ 1.99954307, -0.99977153]),\n",
       "   array([ 1.99955221, -0.9997761 ]),\n",
       "   array([ 1.99956116, -0.99978058]),\n",
       "   array([ 1.99956994, -0.99978497])]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function to minimize and its Jacobian\n",
    "def f_func(z, x_c=2, y_c=-1):\n",
    "    x, y = z\n",
    "    return (x - x_c)**2 + (y - y_c)**2\n",
    "\n",
    "def j_func(z, x_c=2, y_c=-1):\n",
    "    x, y = z\n",
    "    return np.array([2*(x - x_c), 2*(y - y_c)])\n",
    "\n",
    "# Define the gradient descent solver\n",
    "def solve(xs_init, f_func, j_func, learning_rate, precision):\n",
    "    x_current = np.array(xs_init)\n",
    "    iteration = 0\n",
    "    x_history = [x_current]\n",
    "\n",
    "    while True:\n",
    "        jacobian = j_func(x_current)\n",
    "        x_next = x_current - learning_rate * jacobian\n",
    "\n",
    "        # Store the history of x values\n",
    "        x_history.append(x_next)\n",
    "        \n",
    "        # Check if the precision condition is met\n",
    "        if np.linalg.norm(x_next - x_current) < precision:\n",
    "            break\n",
    "\n",
    "        x_current = x_next\n",
    "        iteration += 1\n",
    "\n",
    "    return x_next, iteration, x_history\n",
    "\n",
    "# Example usage of the solve function with a learning rate that is too high and low precision\n",
    "high_learning_rate = 1\n",
    "low_precision = 10\n",
    "\n",
    "# Example usage of the solve function with a suitable learning rate and precision\n",
    "suitable_learning_rate = 0.01\n",
    "suitable_precision = 0.00001\n",
    "\n",
    "# Try the function with both sets of parameters\n",
    "high_lr_result = solve((0, 0), f_func, j_func, high_learning_rate, low_precision)\n",
    "suitable_lr_result = solve((0, 0), f_func, j_func, suitable_learning_rate, suitable_precision)\n",
    "\n",
    "high_lr_result, suitable_lr_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.56926343, -0.78463171]),\n",
       " 75,\n",
       " [array([0, 0]),\n",
       "  array([ 0.04, -0.02]),\n",
       "  array([ 0.0792, -0.0396]),\n",
       "  array([ 0.117616, -0.058808]),\n",
       "  array([ 0.15526368, -0.07763184]),\n",
       "  array([ 0.19215841, -0.0960792 ]),\n",
       "  array([ 0.22831524, -0.11415762]),\n",
       "  array([ 0.26374893, -0.13187447]),\n",
       "  array([ 0.29847395, -0.14923698]),\n",
       "  array([ 0.33250448, -0.16625224]),\n",
       "  array([ 0.36585439, -0.18292719]),\n",
       "  array([ 0.3985373 , -0.19926865]),\n",
       "  array([ 0.43056655, -0.21528328]),\n",
       "  array([ 0.46195522, -0.23097761]),\n",
       "  array([ 0.49271612, -0.24635806]),\n",
       "  array([ 0.52286179, -0.2614309 ]),\n",
       "  array([ 0.55240456, -0.27620228]),\n",
       "  array([ 0.58135647, -0.29067823]),\n",
       "  array([ 0.60972934, -0.30486467]),\n",
       "  array([ 0.63753475, -0.31876738]),\n",
       "  array([ 0.66478406, -0.33239203]),\n",
       "  array([ 0.69148838, -0.34574419]),\n",
       "  array([ 0.71765861, -0.3588293 ]),\n",
       "  array([ 0.74330544, -0.37165272]),\n",
       "  array([ 0.76843933, -0.38421966]),\n",
       "  array([ 0.79307054, -0.39653527]),\n",
       "  array([ 0.81720913, -0.40860456]),\n",
       "  array([ 0.84086495, -0.42043247]),\n",
       "  array([ 0.86404765, -0.43202382]),\n",
       "  array([ 0.8867667 , -0.44338335]),\n",
       "  array([ 0.90903136, -0.45451568]),\n",
       "  array([ 0.93085073, -0.46542537]),\n",
       "  array([ 0.95223372, -0.47611686]),\n",
       "  array([ 0.97318904, -0.48659452]),\n",
       "  array([ 0.99372526, -0.49686263]),\n",
       "  array([ 1.01385076, -0.50692538]),\n",
       "  array([ 1.03357374, -0.51678687]),\n",
       "  array([ 1.05290227, -0.52645113]),\n",
       "  array([ 1.07184422, -0.53592211]),\n",
       "  array([ 1.09040734, -0.54520367]),\n",
       "  array([ 1.10859919, -0.5542996 ]),\n",
       "  array([ 1.12642721, -0.5632136 ]),\n",
       "  array([ 1.14389866, -0.57194933]),\n",
       "  array([ 1.16102069, -0.58051035]),\n",
       "  array([ 1.17780028, -0.58890014]),\n",
       "  array([ 1.19424427, -0.59712214]),\n",
       "  array([ 1.21035939, -0.60517969]),\n",
       "  array([ 1.2261522, -0.6130761]),\n",
       "  array([ 1.24162915, -0.62081458]),\n",
       "  array([ 1.25679657, -0.62839829]),\n",
       "  array([ 1.27166064, -0.63583032]),\n",
       "  array([ 1.28622743, -0.64311371]),\n",
       "  array([ 1.30050288, -0.65025144]),\n",
       "  array([ 1.31449282, -0.65724641]),\n",
       "  array([ 1.32820296, -0.66410148]),\n",
       "  array([ 1.34163891, -0.67081945]),\n",
       "  array([ 1.35480613, -0.67740306]),\n",
       "  array([ 1.36771 , -0.683855]),\n",
       "  array([ 1.3803558, -0.6901779]),\n",
       "  array([ 1.39274869, -0.69637434]),\n",
       "  array([ 1.40489371, -0.70244686]),\n",
       "  array([ 1.41679584, -0.70839792]),\n",
       "  array([ 1.42845992, -0.71422996]),\n",
       "  array([ 1.43989073, -0.71994536]),\n",
       "  array([ 1.45109291, -0.72554646]),\n",
       "  array([ 1.46207105, -0.73103553]),\n",
       "  array([ 1.47282963, -0.73641482]),\n",
       "  array([ 1.48337304, -0.74168652]),\n",
       "  array([ 1.49370558, -0.74685279]),\n",
       "  array([ 1.50383147, -0.75191573]),\n",
       "  array([ 1.51375484, -0.75687742]),\n",
       "  array([ 1.52347974, -0.76173987]),\n",
       "  array([ 1.53301015, -0.76650507]),\n",
       "  array([ 1.54234994, -0.77117497]),\n",
       "  array([ 1.55150294, -0.77575147]),\n",
       "  array([ 1.56047288, -0.78023644]),\n",
       "  array([ 1.56926343, -0.78463171])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suitable_lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Appendix: timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T14:12:24.261532Z",
     "iopub.status.busy": "2024-03-01T14:12:24.260027Z",
     "iopub.status.idle": "2024-03-01T14:12:24.264096Z",
     "shell.execute_reply": "2024-03-01T14:12:24.264096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated on 2024-03-01 22:12:24.262064\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(f\"Generated on {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmk310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef3060a66f05e685ce670116a67026aba95afdffb2461d829b3351d07ec51c58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
